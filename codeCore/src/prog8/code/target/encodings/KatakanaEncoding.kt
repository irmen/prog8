package prog8.code.target.encodings

import com.github.michaelbull.result.Err
import com.github.michaelbull.result.Ok
import com.github.michaelbull.result.Result
import java.io.CharConversionException
import java.nio.charset.Charset

object KatakanaEncoding {
    val charset: Charset = Charset.forName("JIS_X0201")

    fun encode(str: String): Result<List<UByte>, CharConversionException> {
        return try {
            val mapped = str.map { chr ->
                when (chr) {
                    // TODO: Convert regular katakana to halfwidth katakana (java lib doesn't do that for us 
                    //       and simply returns '?' upon reaching a regular katakana character)
                    //       NOTE: we probably need to somehow do that before we reach this `when`, 
                    //             as one regular katakana character often results in two HW katakana characters
                    //             due to differences in how diacritics are handled.

                    '\u0000' -> 0u
                    '\u00a0' -> 0xa0u // $a0 isn't technically a part of JIS X 0201 spec, and so we need to handle this ourselves
                    
                    // Tsu can be interpreted as a smiley
                    'ðŸ™‚' -> 0xc2u
                    'ðŸ˜Š' -> 0xc2u
                    'â˜ºï¸' -> 0xc2u

                    // stuff specific to the cx16 implementation of the standard (non-katakana characters):
                    
                    
                    'ðŸƒ' -> 0xe0u
                    'â˜¹ï¸' -> 0xe2u
                    'ðŸ™' -> 0xe2u
                    'â™¥' -> 0xe3u
                    'â™¦' -> 0xe4u
                    'â™£' -> 0xe5u
                    'â™ ' -> 0xe6u
                    'ðŸ˜£' -> 0xe7u
                    'ðŸ˜–' -> 0xe7u
                    'ðŸ˜«' -> 0xe7u
                    'ðŸ˜µ' -> 0xe8u
                    'ðŸ¤’' -> 0xe8u
                    'ðŸ˜„' -> 0xe9u
                    'ðŸ˜†' -> 0xe9u
                    'ðŸ˜ƒ' -> 0xe9u
                    'ðŸ˜' -> 0xe9u

                    
                    'å¤§' -> 0xeau
                    'ä¸­' -> 0xebu
                    'å°' -> 0xecu
                    'ç™¾' -> 0xedu
                    'åƒ' -> 0xeeu
                    'ä¸‡' -> 0xefu
                    'â™ª' -> 0xf0u
                    'åœŸ' -> 0xf1u
                    'é‡‘' -> 0xf2u
                    'æœ¨' -> 0xf3u
                    'æ°´' -> 0xf4u
                    'ç«' -> 0xf5u
                    'æœˆ' -> 0xf6u
                    'æ—¥' -> 0xf7u
                    'æ™‚' -> 0xf8u
                    'åˆ†' -> 0xf9u
                    'ç§’' -> 0xfau
                    'å¹´' -> 0xfbu
                    'å††' -> 0xfcu
                    'äºº' -> 0xfdu
                    'ç”Ÿ' -> 0xfeu
                    'ã€’' -> 0xffu
                    in '\u8000'..'\u80ff' -> {
                        // special case: take the lower 8 bit hex value directly
                        (chr.code - 0x8000).toUByte()
                    }
                    else -> charset.encode(chr.toString())[0].toUByte()
                }
            }
            Ok(mapped)
        } catch (ce: CharConversionException) {
            Err(ce)
        }
    }

    fun decode(bytes: Iterable<UByte>): Result<String, CharConversionException> {
        return try {
            //idk how is this going to react to $e0-$ff. What is this `decode()` function even used for?
            Ok(String(bytes.map { it.toByte() }.toByteArray(), charset))
        } catch (ce: CharConversionException) {
            Err(ce)
        }
    }
}
